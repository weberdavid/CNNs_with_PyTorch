{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using FashionMNIST to train, test and prune a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from run_classes import RunBuilder, RunManager\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = 'data/FashionMNIST'\n",
    "    , train = True\n",
    "    , download = True\n",
    "    , transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        #, transforms.Normalize(mean = [], std = [])\n",
    "    ]))\n",
    "\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root ='data/FashionMNIST'\n",
    "    , train = False\n",
    "    , download = True\n",
    "    , transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        #, transforms.Normalize(mean = [], std = [])\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Mean and Std for Train and Test Set for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2859), tensor(0.3530))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(train_set, batch_size = len(train_set), num_workers = 1)\n",
    "data = next(iter(loader))\n",
    "data[0].mean(), data[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2869), tensor(0.3524))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(test_set, batch_size = len(test_set), num_workers = 1)\n",
    "data = next(iter(loader))\n",
    "data[0].mean(), data[0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create normalized Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_norm = torchvision.datasets.FashionMNIST(\n",
    "    root = 'data/FashionMNIST'\n",
    "    , train = True\n",
    "    , download = True\n",
    "    , transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        , transforms.Normalize(mean = [.2859], std = [.3524])\n",
    "    ]))\n",
    "\n",
    "\n",
    "test_set_norm = torchvision.datasets.FashionMNIST(\n",
    "    root ='data/FashionMNIST'\n",
    "    , train = False\n",
    "    , download = True\n",
    "    , transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        , transforms.Normalize(mean = [.2869], std = [.3524])\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5)\n",
    "        \n",
    "        #table and formula to calculate the changes of img sizes:\n",
    "        # https://deeplizard.com/learn/video/cin4YcGBh3Q\n",
    "        self.fc1 = nn.Linear(in_features = 12*4*4, out_features = 120) #needed, because the img has the shape\n",
    "                                                                        #(1, 12, 4, 4) when it arrives at the fc\n",
    "                                                                        #because it is flattened, the input is 12*4*4\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        self.out = nn.Linear(in_features = 60, out_features = 10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        t = F.relu(self.fc1(t.reshape(-1, 12 * 4 * 4)))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        \n",
    "        t = self.out(t)\n",
    "        #normally softmax, but is implicitly included in the cross entropy \n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Testing Dics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsets = {\n",
    "    #'not_norm' : train_set,\n",
    "    'norm' : train_set_norm\n",
    "}\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    , batch_size = [1000]\n",
    "    , num_workers = [1]\n",
    "    , epochs = [5]\n",
    "    , trainset = list(trainsets.keys())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainingsloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>epochs</th>\n",
       "      <th>trainset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834753</td>\n",
       "      <td>0.683817</td>\n",
       "      <td>11.147281</td>\n",
       "      <td>14.355769</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.456020</td>\n",
       "      <td>0.826767</td>\n",
       "      <td>12.111821</td>\n",
       "      <td>26.559419</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.378957</td>\n",
       "      <td>0.860817</td>\n",
       "      <td>12.516968</td>\n",
       "      <td>39.162835</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.335699</td>\n",
       "      <td>0.876917</td>\n",
       "      <td>12.605595</td>\n",
       "      <td>51.855749</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.319420</td>\n",
       "      <td>0.881417</td>\n",
       "      <td>12.678778</td>\n",
       "      <td>64.622526</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "0    1      1  0.834753  0.683817       11.147281     14.355769  0.01   \n",
       "1    1      2  0.456020  0.826767       12.111821     26.559419  0.01   \n",
       "2    1      3  0.378957  0.860817       12.516968     39.162835  0.01   \n",
       "3    1      4  0.335699  0.876917       12.605595     51.855749  0.01   \n",
       "4    1      5  0.319420  0.881417       12.678778     64.622526  0.01   \n",
       "\n",
       "   batch_size  num_workers  epochs trainset  \n",
       "0        1000            1       5     norm  \n",
       "1        1000            1       5     norm  \n",
       "2        1000            1       5     norm  \n",
       "3        1000            1       5     norm  \n",
       "4        1000            1       5     norm  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = RunManager()\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    network = CNN()\n",
    "    loader = DataLoader(trainsets[run.trainset]\n",
    "                        , batch_size = run.batch_size\n",
    "                        , num_workers = run.num_workers)\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr = run.lr)\n",
    "    \n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(run.epochs):\n",
    "        m.begin_epoch()\n",
    "        \n",
    "        for batch in loader:\n",
    "            images, labels = batch\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader(test_set_norm\n",
    "                        , batch_size = 1000\n",
    "                        , num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set in %: 86.69\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in testloader:\n",
    "        images, labels = batch\n",
    "        preds = network(images)\n",
    "        predicted = torch.max(preds, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Accuracy on test set in %:', (correct / total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Accuracy of different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/top 75.0 %\n",
      "Accuracy of Trouser 100.0 %\n",
      "Accuracy of Pullover 75.0 %\n",
      "Accuracy of Dress 80.0 %\n",
      "Accuracy of Coat 66.66666666666666 %\n",
      "Accuracy of Sandal 100.0 %\n",
      "Accuracy of Shirt 100.0 %\n",
      "Accuracy of Sneaker 100.0 %\n",
      "Accuracy of Bag 100.0 %\n",
      "Accuracy of Ankle boot 100.0 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(len(train_set.classes)))\n",
    "class_total = list(0. for i in range(len(train_set.classes)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in testloader:\n",
    "        images, labels = batch\n",
    "        preds = network(images)\n",
    "        predicted = torch.max(preds, 1)[1]\n",
    "        c = (predicted == labels)\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "            \n",
    "for i in range(len(train_set.classes)):\n",
    "    print('Accuracy of', train_set.classes[i], class_correct[i] / class_total[i] * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[[[ 0.1406,  0.3241, -0.3158, -0.1282, -0.3015],\n",
      "          [ 0.1322,  0.1489,  0.1558, -0.1870, -0.0869],\n",
      "          [-0.0017, -0.0868,  0.2813, -0.1761,  0.1028],\n",
      "          [ 0.2488, -0.0814, -0.0869, -0.1579,  0.0719],\n",
      "          [ 0.1737, -0.2295,  0.1568,  0.0553, -0.1848]]],\n",
      "\n",
      "\n",
      "        [[[-0.1738,  0.1401,  0.3369,  0.1556,  0.1386],\n",
      "          [-0.2808,  0.3735, -0.0281, -0.2210,  0.0766],\n",
      "          [-0.1657,  0.2196, -0.0553, -0.0506, -0.1463],\n",
      "          [-0.0950,  0.0341, -0.1670,  0.0759,  0.1428],\n",
      "          [-0.0037,  0.2186, -0.0685, -0.0528, -0.0574]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0083,  0.1842, -0.0096,  0.1312, -0.2054],\n",
      "          [-0.0536,  0.0767,  0.2360,  0.0437, -0.0317],\n",
      "          [ 0.2464, -0.2670,  0.1162,  0.0054,  0.0795],\n",
      "          [ 0.0985, -0.1735,  0.1174,  0.0308,  0.0866],\n",
      "          [ 0.3539, -0.1757, -0.1554,  0.2130,  0.0505]]],\n",
      "\n",
      "\n",
      "        [[[-0.1154, -0.0993,  0.2199,  0.1610, -0.0416],\n",
      "          [-0.4733, -0.1686,  0.2232,  0.2862,  0.0517],\n",
      "          [-0.2512, -0.3575,  0.3998, -0.0255,  0.1495],\n",
      "          [-0.3235, -0.1127,  0.3196,  0.0638, -0.0233],\n",
      "          [-0.1602, -0.2415,  0.2707,  0.1636, -0.0908]]],\n",
      "\n",
      "\n",
      "        [[[-0.1453, -0.0747, -0.0023,  0.0447,  0.0616],\n",
      "          [ 0.3017,  0.2233,  0.0989,  0.0418, -0.1503],\n",
      "          [ 0.1529,  0.3720,  0.1542,  0.0515, -0.0947],\n",
      "          [-0.1100, -0.2458,  0.1382,  0.1774, -0.0481],\n",
      "          [-0.1937, -0.3933, -0.4379, -0.2214,  0.1370]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0562,  0.0723, -0.1495, -0.1005, -0.1062],\n",
      "          [-0.1550, -0.2306, -0.0242, -0.0183, -0.1662],\n",
      "          [-0.1727, -0.0220, -0.1373, -0.2988,  0.0826],\n",
      "          [-0.2229, -0.3314, -0.2944, -0.1848,  0.0023],\n",
      "          [-0.1290, -0.3049, -0.0821, -0.2046, -0.1334]]]], requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([-0.0450,  0.2849, -0.0798,  0.0157, -0.0742, -0.4180],\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "module = network.conv1\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#The layer does not contain any buffers at the moment\n",
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) First, select a pruning method among those available in torch.nn.utils.prune or implement your own by using BasePruningMethod  \n",
    "2) Then, specify module and name of parameter to prune.  \n",
    "3) Use keyword arguments for the specific pruning techniques, specifying pruning parameters.  \n",
    "  \n",
    "Let's prune 30% of our network randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prune the weights of the conv1 layer by 30%\n",
    "# when amount is integer, results in number of connections pruned.\n",
    "prune.random_unstructured(module, name = 'weight', amount = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning removes the `weight` from the parameters and gives a new parameter calles `weight_orig` which stores the unpruned version of the tensor. Bias was not pruned, so it stays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([-0.0450,  0.2849, -0.0798,  0.0157, -0.0742, -0.4180],\n",
      "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[[[ 0.1406,  0.3241, -0.3158, -0.1282, -0.3015],\n",
      "          [ 0.1322,  0.1489,  0.1558, -0.1870, -0.0869],\n",
      "          [-0.0017, -0.0868,  0.2813, -0.1761,  0.1028],\n",
      "          [ 0.2488, -0.0814, -0.0869, -0.1579,  0.0719],\n",
      "          [ 0.1737, -0.2295,  0.1568,  0.0553, -0.1848]]],\n",
      "\n",
      "\n",
      "        [[[-0.1738,  0.1401,  0.3369,  0.1556,  0.1386],\n",
      "          [-0.2808,  0.3735, -0.0281, -0.2210,  0.0766],\n",
      "          [-0.1657,  0.2196, -0.0553, -0.0506, -0.1463],\n",
      "          [-0.0950,  0.0341, -0.1670,  0.0759,  0.1428],\n",
      "          [-0.0037,  0.2186, -0.0685, -0.0528, -0.0574]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0083,  0.1842, -0.0096,  0.1312, -0.2054],\n",
      "          [-0.0536,  0.0767,  0.2360,  0.0437, -0.0317],\n",
      "          [ 0.2464, -0.2670,  0.1162,  0.0054,  0.0795],\n",
      "          [ 0.0985, -0.1735,  0.1174,  0.0308,  0.0866],\n",
      "          [ 0.3539, -0.1757, -0.1554,  0.2130,  0.0505]]],\n",
      "\n",
      "\n",
      "        [[[-0.1154, -0.0993,  0.2199,  0.1610, -0.0416],\n",
      "          [-0.4733, -0.1686,  0.2232,  0.2862,  0.0517],\n",
      "          [-0.2512, -0.3575,  0.3998, -0.0255,  0.1495],\n",
      "          [-0.3235, -0.1127,  0.3196,  0.0638, -0.0233],\n",
      "          [-0.1602, -0.2415,  0.2707,  0.1636, -0.0908]]],\n",
      "\n",
      "\n",
      "        [[[-0.1453, -0.0747, -0.0023,  0.0447,  0.0616],\n",
      "          [ 0.3017,  0.2233,  0.0989,  0.0418, -0.1503],\n",
      "          [ 0.1529,  0.3720,  0.1542,  0.0515, -0.0947],\n",
      "          [-0.1100, -0.2458,  0.1382,  0.1774, -0.0481],\n",
      "          [-0.1937, -0.3933, -0.4379, -0.2214,  0.1370]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0562,  0.0723, -0.1495, -0.1005, -0.1062],\n",
      "          [-0.1550, -0.2306, -0.0242, -0.0183, -0.1662],\n",
      "          [-0.1727, -0.0220, -0.1373, -0.2988,  0.0826],\n",
      "          [-0.2229, -0.3314, -0.2944, -0.1848,  0.0023],\n",
      "          [-0.1290, -0.3049, -0.0821, -0.2046, -0.1334]]]], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mask, that prunes the parameter is stored as a module buffer named `weight_mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[[[1., 1., 1., 0., 0.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 0., 1., 0., 1.],\n",
      "          [0., 1., 1., 1., 1.],\n",
      "          [1., 1., 0., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0., 1., 0.],\n",
      "          [1., 0., 1., 0., 1.],\n",
      "          [1., 0., 1., 0., 1.],\n",
      "          [1., 1., 1., 1., 0.],\n",
      "          [1., 1., 1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 0.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 0., 1.],\n",
      "          [1., 1., 1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 0., 0.],\n",
      "          [0., 1., 1., 0., 1.],\n",
      "          [1., 1., 0., 1., 0.],\n",
      "          [1., 0., 1., 1., 1.],\n",
      "          [1., 0., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1., 1., 1.],\n",
      "          [1., 1., 0., 1., 0.],\n",
      "          [0., 0., 0., 1., 1.],\n",
      "          [0., 0., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0., 1., 1.],\n",
      "          [1., 0., 1., 0., 1.],\n",
      "          [0., 1., 0., 0., 1.],\n",
      "          [1., 1., 0., 1., 0.],\n",
      "          [0., 0., 0., 1., 1.]]]]))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But where is the updated weight stored now? As it is required for the forward-pass to function properly, the pruned version of the weights is stored in `weight`. It can be accessed as an attribute and is NOT stored in the parameter of the module anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1406,  0.3241, -0.3158, -0.0000, -0.0000],\n",
      "          [ 0.1322,  0.1489,  0.1558, -0.1870, -0.0869],\n",
      "          [-0.0017, -0.0000,  0.2813, -0.0000,  0.1028],\n",
      "          [ 0.0000, -0.0814, -0.0869, -0.1579,  0.0719],\n",
      "          [ 0.1737, -0.2295,  0.0000,  0.0553, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1738,  0.1401,  0.0000,  0.1556,  0.0000],\n",
      "          [-0.2808,  0.0000, -0.0281, -0.0000,  0.0766],\n",
      "          [-0.1657,  0.0000, -0.0553, -0.0000, -0.1463],\n",
      "          [-0.0950,  0.0341, -0.1670,  0.0759,  0.0000],\n",
      "          [-0.0037,  0.2186, -0.0685, -0.0000, -0.0574]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0083,  0.1842, -0.0096,  0.1312, -0.0000],\n",
      "          [-0.0536,  0.0767,  0.2360,  0.0437, -0.0317],\n",
      "          [ 0.2464, -0.2670,  0.1162,  0.0054,  0.0795],\n",
      "          [ 0.0985, -0.1735,  0.1174,  0.0000,  0.0866],\n",
      "          [ 0.3539, -0.1757, -0.1554,  0.2130,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1154, -0.0993,  0.2199,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.1686,  0.2232,  0.0000,  0.0517],\n",
      "          [-0.2512, -0.3575,  0.0000, -0.0255,  0.0000],\n",
      "          [-0.3235, -0.0000,  0.3196,  0.0638, -0.0233],\n",
      "          [-0.1602, -0.0000,  0.2707,  0.1636, -0.0908]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0747, -0.0023,  0.0447,  0.0616],\n",
      "          [ 0.3017,  0.2233,  0.0000,  0.0418, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0515, -0.0947],\n",
      "          [-0.0000, -0.0000,  0.1382,  0.1774, -0.0481],\n",
      "          [-0.1937, -0.3933, -0.4379, -0.2214,  0.1370]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0562,  0.0723, -0.0000, -0.1005, -0.1062],\n",
      "          [-0.1550, -0.0000, -0.0242, -0.0000, -0.1662],\n",
      "          [-0.0000, -0.0220, -0.0000, -0.0000,  0.0826],\n",
      "          [-0.2229, -0.3314, -0.0000, -0.1848,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.2046, -0.1334]]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarized:\n",
    "* `name + _mask` is the binary mask which indicates pruning\n",
    "* `name` usually containing original parameters is replaced with the pruned params\n",
    "* `name + _orig` is a new parameter that stores the unpruned (original) parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning is applied prior to each forward pass with the `forward_pre_hooks`. It is acquired when the module is pruned. Only one hook is present, as only one parameter was pruned so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(0, <torch.nn.utils.prune.RandomUnstructured object at 0x7fa91e49cad0>)])\n"
     ]
    }
   ],
   "source": [
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prune the bias as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pruning three smallest entries of the bias with L1 Norm.\n",
    "prune.l1_unstructured(module, name = 'bias', amount = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(0, <torch.nn.utils.prune.RandomUnstructured object at 0x7fa91e49cad0>), (1, <torch.nn.utils.prune.L1Unstructured object at 0x7fa933226510>)])\n"
     ]
    }
   ],
   "source": [
    "print(module._forward_pre_hooks) #we have 2 hooks now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a `bias_orig` as well, `bias_mask` and two forward hooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same parameter can be tuned multiple times - the created masks are then applied in series. This mask-combination is handled by the `compute_mask` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using structured pruning along the output channels of conv1, based on L2 norm (?).\n",
    "prune.ln_structured(module, name = \"weight\", amount = 0.5, n = 2, dim = 0) #half of the channels is zerod out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0083,  0.1842, -0.0096,  0.1312, -0.0000],\n",
      "          [-0.0536,  0.0767,  0.2360,  0.0437, -0.0317],\n",
      "          [ 0.2464, -0.2670,  0.1162,  0.0054,  0.0795],\n",
      "          [ 0.0985, -0.1735,  0.1174,  0.0000,  0.0866],\n",
      "          [ 0.3539, -0.1757, -0.1554,  0.2130,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1154, -0.0993,  0.2199,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.1686,  0.2232,  0.0000,  0.0517],\n",
      "          [-0.2512, -0.3575,  0.0000, -0.0255,  0.0000],\n",
      "          [-0.3235, -0.0000,  0.3196,  0.0638, -0.0233],\n",
      "          [-0.1602, -0.0000,  0.2707,  0.1636, -0.0908]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0747, -0.0023,  0.0447,  0.0616],\n",
      "          [ 0.3017,  0.2233,  0.0000,  0.0418, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0515, -0.0947],\n",
      "          [-0.0000, -0.0000,  0.1382,  0.1774, -0.0481],\n",
      "          [-0.1937, -0.3933, -0.4379, -0.2214,  0.1370]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000]]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<torch.nn.utils.prune.RandomUnstructured object at 0x7fa91e49cad0>, <torch.nn.utils.prune.LnStructured object at 0x7fa9332265d0>]\n"
     ]
    }
   ],
   "source": [
    "#History of pruning is further written:\n",
    "for hook in module._forward_pre_hooks.values():\n",
    "    if hook._tensor_name == 'weight':\n",
    "        break\n",
    "        \n",
    "print(list(hook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'out.weight', 'out.bias'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting all relevant tensors of our network:\n",
    "network.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove pruning re-parametrization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= making pruning permanent, removing forward_pre_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_orig', Parameter containing:\n",
      "tensor([[[[ 0.1406,  0.3241, -0.3158, -0.1282, -0.3015],\n",
      "          [ 0.1322,  0.1489,  0.1558, -0.1870, -0.0869],\n",
      "          [-0.0017, -0.0868,  0.2813, -0.1761,  0.1028],\n",
      "          [ 0.2488, -0.0814, -0.0869, -0.1579,  0.0719],\n",
      "          [ 0.1737, -0.2295,  0.1568,  0.0553, -0.1848]]],\n",
      "\n",
      "\n",
      "        [[[-0.1738,  0.1401,  0.3369,  0.1556,  0.1386],\n",
      "          [-0.2808,  0.3735, -0.0281, -0.2210,  0.0766],\n",
      "          [-0.1657,  0.2196, -0.0553, -0.0506, -0.1463],\n",
      "          [-0.0950,  0.0341, -0.1670,  0.0759,  0.1428],\n",
      "          [-0.0037,  0.2186, -0.0685, -0.0528, -0.0574]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0083,  0.1842, -0.0096,  0.1312, -0.2054],\n",
      "          [-0.0536,  0.0767,  0.2360,  0.0437, -0.0317],\n",
      "          [ 0.2464, -0.2670,  0.1162,  0.0054,  0.0795],\n",
      "          [ 0.0985, -0.1735,  0.1174,  0.0308,  0.0866],\n",
      "          [ 0.3539, -0.1757, -0.1554,  0.2130,  0.0505]]],\n",
      "\n",
      "\n",
      "        [[[-0.1154, -0.0993,  0.2199,  0.1610, -0.0416],\n",
      "          [-0.4733, -0.1686,  0.2232,  0.2862,  0.0517],\n",
      "          [-0.2512, -0.3575,  0.3998, -0.0255,  0.1495],\n",
      "          [-0.3235, -0.1127,  0.3196,  0.0638, -0.0233],\n",
      "          [-0.1602, -0.2415,  0.2707,  0.1636, -0.0908]]],\n",
      "\n",
      "\n",
      "        [[[-0.1453, -0.0747, -0.0023,  0.0447,  0.0616],\n",
      "          [ 0.3017,  0.2233,  0.0989,  0.0418, -0.1503],\n",
      "          [ 0.1529,  0.3720,  0.1542,  0.0515, -0.0947],\n",
      "          [-0.1100, -0.2458,  0.1382,  0.1774, -0.0481],\n",
      "          [-0.1937, -0.3933, -0.4379, -0.2214,  0.1370]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0562,  0.0723, -0.1495, -0.1005, -0.1062],\n",
      "          [-0.1550, -0.2306, -0.0242, -0.0183, -0.1662],\n",
      "          [-0.1727, -0.0220, -0.1373, -0.2988,  0.0826],\n",
      "          [-0.2229, -0.3314, -0.2944, -0.1848,  0.0023],\n",
      "          [-0.1290, -0.3049, -0.0821, -0.2046, -0.1334]]]], requires_grad=True)), ('bias_orig', Parameter containing:\n",
      "tensor([-0.0450,  0.2849, -0.0798,  0.0157, -0.0742, -0.4180],\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 0.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 0., 1.],\n",
      "          [1., 1., 1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 0., 0.],\n",
      "          [0., 1., 1., 0., 1.],\n",
      "          [1., 1., 0., 1., 0.],\n",
      "          [1., 0., 1., 1., 1.],\n",
      "          [1., 0., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1., 1., 1.],\n",
      "          [1., 1., 0., 1., 0.],\n",
      "          [0., 0., 0., 1., 1.],\n",
      "          [0., 0., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]]])), ('bias_mask', tensor([0., 1., 1., 0., 0., 1.]))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0083,  0.1842, -0.0096,  0.1312, -0.0000],\n",
      "          [-0.0536,  0.0767,  0.2360,  0.0437, -0.0317],\n",
      "          [ 0.2464, -0.2670,  0.1162,  0.0054,  0.0795],\n",
      "          [ 0.0985, -0.1735,  0.1174,  0.0000,  0.0866],\n",
      "          [ 0.3539, -0.1757, -0.1554,  0.2130,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1154, -0.0993,  0.2199,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.1686,  0.2232,  0.0000,  0.0517],\n",
      "          [-0.2512, -0.3575,  0.0000, -0.0255,  0.0000],\n",
      "          [-0.3235, -0.0000,  0.3196,  0.0638, -0.0233],\n",
      "          [-0.1602, -0.0000,  0.2707,  0.1636, -0.0908]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0747, -0.0023,  0.0447,  0.0616],\n",
      "          [ 0.3017,  0.2233,  0.0000,  0.0418, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0515, -0.0947],\n",
      "          [-0.0000, -0.0000,  0.1382,  0.1774, -0.0481],\n",
      "          [-0.1937, -0.3933, -0.4379, -0.2214,  0.1370]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000]]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias_orig', Parameter containing:\n",
      "tensor([-0.0450,  0.2849, -0.0798,  0.0157, -0.0742, -0.4180],\n",
      "       requires_grad=True)), ('weight', Parameter containing:\n",
      "tensor([[[[ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0083,  0.1842, -0.0096,  0.1312, -0.0000],\n",
      "          [-0.0536,  0.0767,  0.2360,  0.0437, -0.0317],\n",
      "          [ 0.2464, -0.2670,  0.1162,  0.0054,  0.0795],\n",
      "          [ 0.0985, -0.1735,  0.1174,  0.0000,  0.0866],\n",
      "          [ 0.3539, -0.1757, -0.1554,  0.2130,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1154, -0.0993,  0.2199,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.1686,  0.2232,  0.0000,  0.0517],\n",
      "          [-0.2512, -0.3575,  0.0000, -0.0255,  0.0000],\n",
      "          [-0.3235, -0.0000,  0.3196,  0.0638, -0.0233],\n",
      "          [-0.1602, -0.0000,  0.2707,  0.1636, -0.0908]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0747, -0.0023,  0.0447,  0.0616],\n",
      "          [ 0.3017,  0.2233,  0.0000,  0.0418, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0515, -0.0947],\n",
      "          [-0.0000, -0.0000,  0.1382,  0.1774, -0.0481],\n",
      "          [-0.1937, -0.3933, -0.4379, -0.2214,  0.1370]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000]]]], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "#Removing reparametrization\n",
    "prune.remove(module, 'weight')\n",
    "print(list(module.named_parameters())) #under named parameters, 'weight' is now mentioned\n",
    "                                        #, instead of weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias_mask', tensor([0., 1., 1., 0., 0., 1.]))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pruning multiple parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prune modules according to their type\n",
    "for name, module in network.named_modules():\n",
    "    \n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.l1_unstructured(module, name = 'weight', amount = .2)\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module, name = 'weight', amount = .1)\n",
    "        \n",
    "    #..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "local = pruning tensors one by one  \n",
    "global = removing a certain percentage of connections across the whole model. This means that sparsity may be higher or lower in certain layers, but overall being a specific defined percentage. This is done with `global_unstructured`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (network.conv1, 'weight')\n",
    "    #, ... \n",
    ")\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method = prune.L1Unstructured,\n",
    "    amount = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For custom pruning methods, have a look here: https://pytorch.org/tutorials/intermediate/pruning_tutorial.html (at the bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipy_base",
   "language": "python",
   "name": "ipy_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
