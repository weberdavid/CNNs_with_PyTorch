{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard is a nice dashboard for all kind of metrics for the network we are creating. Further, it helps doing hyperparameter tuning and stuff like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let tensorboard running on localhost:\n",
    "#tensorboard --logdir=runs\n",
    "\n",
    "#creats a runs folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(predictions, labels):\n",
    "    return predictions.argmax(dim = 1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5)\n",
    "        \n",
    "        #table and formula to calculate the changes of img sizes:\n",
    "        # https://deeplizard.com/learn/video/cin4YcGBh3Q\n",
    "        self.fc1 = nn.Linear(in_features = 12*4*4, out_features = 120) #needed, because the img has the shape\n",
    "                                                                        #(1, 12, 4, 4) when it arrives at the fc\n",
    "                                                                        #because it is flattened, the input is 12*4*4\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        self.out = nn.Linear(in_features = 60, out_features = 10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        t = F.relu(self.fc1(t.reshape(-1, 12 * 4 * 4)))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        \n",
    "        t = self.out(t)\n",
    "        #normally softmax, but is implicitly included in the cross entropy \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = \"./data/FashionMNIST\"\n",
    "    , train = True\n",
    "    , download = True\n",
    "    , transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting with Tensorboard:\n",
    "tb = SummaryWriter() #creating a new instance\n",
    "\n",
    "network = Network()\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "#create a grid of images\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "#pass a tag and the data\n",
    "tb.add_image('images', grid)\n",
    "\n",
    "#pass our network and images tensor\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "#close SummaryWriter\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Process with TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.01, 0.001], [10, 100, 1000], [True, False], [1]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = dict(\n",
    "    lr = [.01, .001]\n",
    "    , batch_size = [10, 100, 1000]\n",
    "    , shuffle = [True, False]\n",
    "    , epochs = [1]\n",
    ")\n",
    "\n",
    "param_values = [v for v in parameters.values()]\n",
    "param_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of runs 1 epoch 0 total_correct 46030 loss 37573.828353344 accuracy% 76.71666666666667\n",
      "amount of runs 2 epoch 0 total_correct 47244 loss 35031.88015679829 accuracy% 78.74\n",
      "amount of runs 3 epoch 0 total_correct 46380 loss 35839.84170258045 accuracy% 77.3\n",
      "amount of runs 4 epoch 0 total_correct 47801 loss 32675.0136628747 accuracy% 79.66833333333334\n",
      "amount of runs 5 epoch 0 total_correct 36598 loss 60045.03780603409 accuracy% 60.99666666666666\n",
      "amount of runs 6 epoch 0 total_correct 33124 loss 70813.6677145958 accuracy% 55.20666666666667\n",
      "amount of runs 7 epoch 0 total_correct 46423 loss 35896.46309865173 accuracy% 77.37166666666667\n",
      "amount of runs 8 epoch 0 total_correct 46602 loss 35320.90608856641 accuracy% 77.66999999999999\n",
      "amount of runs 9 epoch 0 total_correct 42936 loss 45168.02119016647 accuracy% 71.56\n",
      "amount of runs 10 epoch 0 total_correct 43087 loss 45432.783845067024 accuracy% 71.81166666666667\n",
      "amount of runs 11 epoch 0 total_correct 27544 loss 99347.93251752853 accuracy% 45.906666666666666\n",
      "amount of runs 12 epoch 0 total_correct 26157 loss 94747.24924564362 accuracy% 43.595\n"
     ]
    }
   ],
   "source": [
    "#run counter, how many have been done\n",
    "runs = 0\n",
    "\n",
    "#make our life easy - now we can add as many hyperparams to our dict as we want\n",
    "for lr, batch_size, shuffle, epochs in product(*param_values): #creates kartesian product of the params - every with every\n",
    "    \n",
    "    network = Network()\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "    optimizer = optim.Adam(network.parameters(), lr = lr)\n",
    "\n",
    "    images, labels = next(iter(train_loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    #add TB stuff\n",
    "    #uniquely identify this run, as we name this run\n",
    "    comment = f' batch_size = {batch_size} lr = {lr} shuffle = {shuffle}'\n",
    "    tb = SummaryWriter(comment = comment) #creating a new instance\n",
    "    tb.add_image('images', grid)\n",
    "    tb.add_graph(network, images)\n",
    "\n",
    "    for epoch in range(epochs): #how many epochs\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        for batch in train_loader: #get the batch\n",
    "            images, labels = batch\n",
    "\n",
    "            preds = network(images) #pass batch to network\n",
    "            loss = F.cross_entropy(preds, labels) #calculate loss\n",
    "\n",
    "            optimizer.zero_grad() #make gradients zero\n",
    "            loss.backward() #calculate gradients\n",
    "            optimizer.step() #update weights\n",
    "\n",
    "            total_loss += loss.item() * batch_size #multiply by batchsize for comparability in tensorboard\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        #Add tensorboard KPIs\n",
    "        #name of value, which scalar, epoch for when the value is occuring\n",
    "        tb.add_scalar('Loss', total_loss, epoch)\n",
    "        tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "        tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "        #name of value, set of values\n",
    "        #tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\n",
    "        #tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\n",
    "        #tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)\n",
    "\n",
    "        #this can be done better:\n",
    "\n",
    "        for name, weight in network.named_parameters(): #gives parameter and parameter name as tuple\n",
    "            tb.add_histogram(name, weight, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "        \n",
    "        runs += 1\n",
    "        print('run', runs, 'epoch', epoch, 'total_correct', total_correct, 'loss', total_loss, 'accuracy%', total_correct / len(train_set) * 100)\n",
    "\n",
    "    tb.close()\n",
    "\n",
    "#With all those runs, we can easily compare hyperparameters in TB, as we see diagrams with it.\n",
    "#That makes it easy to choose the best hyperparams. Use regex in TB to filter specific params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this can be done way nicer with a RunBuilder class - which is in a separat notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipy_base",
   "language": "python",
   "name": "ipy_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
