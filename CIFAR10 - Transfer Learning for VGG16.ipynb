{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use VGG16 for Transfer Learning on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models #vgg16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading and preparing the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)) #VGG16 takes 224px sized imgs\n",
    "    , transforms.ToTensor()\n",
    "    , transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root = './data/CIFAR10'\n",
    "                                      , train = True\n",
    "                                      , download = True\n",
    "                                      , transform = transform)\n",
    "\n",
    "trainset, validset = torch.utils.data.random_split(dataset, [40000, 10000])\n",
    "\n",
    "trainloader = DataLoader(trainset\n",
    "                        , batch_size = 32\n",
    "                        , shuffle = True\n",
    "                        , num_workers = 1)\n",
    "\n",
    "validloader = DataLoader(validset\n",
    "                        , batch_size = 32\n",
    "                        , shuffle = True\n",
    "                        , num_workers = 1)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data/CIFAR10'\n",
    "                                      , train = False\n",
    "                                      , download = True\n",
    "                                      , transform = transform)\n",
    "\n",
    "testloader = DataLoader(testset\n",
    "                       , batch_size = 32\n",
    "                       , shuffle = False\n",
    "                       , num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Prepare VGG16 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16(pretrained = True)\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see that the last layer classifies 1000 classes - we only need 10\n",
    "#Further, we freeze conv layers, as they learned from the imagenet dataset - this\n",
    "# can be played with\n",
    "\n",
    "vgg16.classifier[6].out_features = 10\n",
    "\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_dataloader):\n",
    "    model.eval()\n",
    "    val_running_loss = 0\n",
    "    val_running_corr = 0\n",
    "    for batch in val_dataloader:\n",
    "        images, labels = batch\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, labels)\n",
    "        \n",
    "        val_running_loss += loss.item()\n",
    "        val_running_corr += preds.argmax(dim = 1).eq(labels).sum().item()\n",
    "        \n",
    "    val_loss = val_running_loss / len(val_dataloader.dataset)\n",
    "    val_accuracy = 100 * val_running_corr / len(val_dataloader.dataset)\n",
    "    \n",
    "    print(f'Valid Loss: {val_loss:.4f}, Valid Acc %: {val_accuracy:.2f}')\n",
    "    \n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader):\n",
    "    model.train()\n",
    "    train_running_loss = 0\n",
    "    train_running_corr = 0\n",
    "    for batch in train_dataloader:\n",
    "        images, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, labels)\n",
    "        \n",
    "        train_running_loss += loss.item()\n",
    "        train_running_corr += preds.argmax(dim = 1).eq(labels).sum().item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    train_loss = train_running_loss / len(train_dataloader.dataset)\n",
    "    train_accuracy = 100 * train_running_corr / len(train_dataloader.dataset)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc %: {train_accuracy:.2f}')\n",
    "    \n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop - not trainable on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(vgg16.classifier.parameters()\n",
    "                     , lr = 0.01\n",
    "                     , momentum = 0.9) #???\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_accuracy = [], []\n",
    "val_loss, val_accuracy = [], []\n",
    "\n",
    "for epoch in range(10):\n",
    "    print('Epoch ', epoch)\n",
    "    train_epoch_loss, train_epoch_acc = train(vgg16, trainloader)\n",
    "    val_epoch_loss, val_epoch_acc = validate(vgg16, validloader)\n",
    "    \n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_accuracy.append(train_epoch_acc)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loop - not possible on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    test_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            images, labels = batch\n",
    "            preds = model(images)\n",
    "        \n",
    "            test_correct += preds.argmax(dim = 1).eq(labels).sum().item()\n",
    "    \n",
    "    test_accuracy = 100 * test_correct / len(test_loader.dataset)    \n",
    "    print('Accuracy on TestSet in %:', test_accuracy)\n",
    "    \n",
    "    #return test_correct, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(vgg16, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipy_base",
   "language": "python",
   "name": "ipy_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
