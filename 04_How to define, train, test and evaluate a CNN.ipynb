{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tutorial & DeepLizard CNN Series on YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uninitialized Matrix, is declared but does not contain definite known values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.1704e-41],\n",
      "        [ 0.0000e+00,  2.2369e+08,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [        nan,         nan, -4.5862e+21]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly initialized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7283, 0.1690, 0.4126],\n",
      "        [0.3335, 0.5632, 0.1026],\n",
      "        [0.0210, 0.8484, 0.3009],\n",
      "        [0.8955, 0.4886, 0.2778],\n",
      "        [0.5867, 0.2636, 0.2787]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a matrix with zeros and data type long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype = torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a tensor directly from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create tensor based on existing one, these methods reuse properties of the input sensor like the dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.new_zeros(5, 2, dtype = torch.float64) #new_* (ones, zeros, ...) take in the size\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5782,  1.7321],\n",
      "        [-0.5274, -0.6841],\n",
      "        [ 0.0571,  0.0442],\n",
      "        [-0.7754,  0.8682],\n",
      "        [-0.5045, -0.5877]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype = torch.double) #dtype is overriden \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addition can be done in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0250,  2.5345],\n",
      "        [-0.3672, -0.3670],\n",
      "        [ 0.9669,  0.3353],\n",
      "        [-0.3124,  1.4227],\n",
      "        [-0.2825, -0.3679]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 2) #first syntax\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4350e+00,  2.6342e+00],\n",
       "        [-3.8693e-01, -8.4006e-02],\n",
       "        [ 9.8195e-02,  7.6191e-01],\n",
       "        [ 3.8493e-02,  9.8922e-01],\n",
       "        [ 5.5112e-05, -3.2012e-01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, y) #second syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.4350e+00,  2.6342e+00],\n",
      "        [-3.8693e-01, -8.4006e-02],\n",
      "        [ 9.8195e-02,  7.6191e-01],\n",
      "        [ 3.8493e-02,  9.8922e-01],\n",
      "        [ 5.5112e-05, -3.2012e-01]])\n"
     ]
    }
   ],
   "source": [
    "#providing an output tensor is also possible\n",
    "xy = torch.zeros(5, 2)\n",
    "torch.add(x, y, out = xy)\n",
    "print(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.6149e-08,  1.7436e-08],\n",
      "        [ 8.1499e-09, -2.4920e-08],\n",
      "        [-1.6608e-09, -8.6048e-10],\n",
      "        [-2.8191e-08,  7.3443e-09],\n",
      "        [ 2.2290e-08,  4.2212e-09]])\n"
     ]
    }
   ],
   "source": [
    "#...or you can do it in-line: every operation then ends with a '_'\n",
    "y.add_(x) #.t_() 'transform', .copy_(x) 'copys x values'\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy like Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.7321, -0.6841,  0.0442,  0.8682, -0.5877], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing / -shaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8431, 0.5812, 0.3966, 0.3668, 0.7176],\n",
      "        [0.6199, 0.3733, 0.5300, 0.7550, 0.4253],\n",
      "        [0.5757, 0.9736, 0.5893, 0.9198, 0.7944],\n",
      "        [0.2366, 0.0377, 0.3292, 0.3925, 0.8500],\n",
      "        [0.1079, 0.5784, 0.4094, 0.1009, 0.9620]]) tensor([0.8431, 0.5812, 0.3966, 0.3668, 0.7176, 0.6199, 0.3733, 0.5300, 0.7550,\n",
      "        0.4253, 0.5757, 0.9736, 0.5893, 0.9198, 0.7944, 0.2366, 0.0377, 0.3292,\n",
      "        0.3925, 0.8500, 0.1079, 0.5784, 0.4094, 0.1009, 0.9620]) tensor([[0.8431, 0.5812, 0.3966, 0.3668, 0.7176],\n",
      "        [0.6199, 0.3733, 0.5300, 0.7550, 0.4253],\n",
      "        [0.5757, 0.9736, 0.5893, 0.9198, 0.7944],\n",
      "        [0.2366, 0.0377, 0.3292, 0.3925, 0.8500],\n",
      "        [0.1079, 0.5784, 0.4094, 0.1009, 0.9620]])\n",
      "torch.Size([5, 5]) torch.Size([25]) torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,5)\n",
    "y = x.view(25)\n",
    "z = x.view(-1, 5) #-1 means to infer (ableiten) from other dimensions, shape depends on second parameter\n",
    "print(x, y, z)\n",
    "print(x.shape, y.shape, z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use .item() to select tensor values as python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8376832008361816"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1, 3].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8377)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#... instead of\n",
    "x[1, 3] #or x[1][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Array <> Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a NumPy array and a tensor share the memory location, meaning that a change of one results in a change of the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5008, 0.0641, 0.6698, 0.1802],\n",
      "        [0.6955, 0.1084, 0.2223, 0.1705],\n",
      "        [0.6962, 0.1849, 0.2312, 0.5964]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3, 4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.500763   0.06406945 0.66979754 0.18023556]\n",
      " [0.69545645 0.10835159 0.22226119 0.17049241]\n",
      " [0.6962485  0.18492407 0.23120284 0.5963593 ]]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5008, 2.0641, 2.6698, 2.1802],\n",
      "        [2.6955, 2.1084, 2.2223, 2.1705],\n",
      "        [2.6962, 2.1849, 2.2312, 2.5964]])\n"
     ]
    }
   ],
   "source": [
    "a = a.add_(2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.500763  2.0640695 2.6697974 2.1802356]\n",
      " [2.6954565 2.1083517 2.2222612 2.1704924]\n",
      " [2.6962485 2.1849241 2.2312028 2.5963593]]\n"
     ]
    }
   ],
   "source": [
    "print(b) #numpy array changed according to \"a\" computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ...this works the other way around as well (from np to torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.] \n",
      " tensor([1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(4)\n",
    "b = torch.from_numpy(a)\n",
    "print(a, '\\n', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. 3.] \n",
      " tensor([3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np.add(a, 2, out = a)\n",
    "print(a, '\\n', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  bringing Tensors to CUDA with .to()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does not work for me, no CUDA\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x, device = device) #one way\n",
    "    x = x.to(device) #second possibility\n",
    "    z = x+y\n",
    "    z.to(\"cpu\", torch.double) #.to() can also override dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd: Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### = automatic differentiation for all operations on Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#creating a tensor and setting requires_grad to true to track computation\n",
    "x = torch.ones(2, 2, requires_grad = True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x7ff16e77b210>\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward() # no need to give a tensor within backward, because out contains a single scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vector-Jacobian product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 65.3840, 581.7717, 856.9518], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, requires_grad = True)\n",
    "y = x * 2\n",
    "\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(torch.rand(3, dtype = torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([915.3042, 727.2310, 131.0215])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#stop autograd on tracking history on tensors\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.detach() makes new Tensor that does not require grad\n",
    "r = x.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module): #required\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__() #extend the nn Module from PyTorch (inheritance)\n",
    "        #in_channels= depends on number of colorspace; out_channels=feature maps, number of filters;  kernel_size=filter size\n",
    "        #out_channels are often increased among the layers\n",
    "        #those are all hyperparameters, weights are learnable parameters\n",
    "        #optional: stride=(), tells how much the filter should move right and down\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5) #kernel = filter, has height and width\n",
    "        self.conv2 = nn.Conv2d(6, 12, 5)\n",
    "        \n",
    "        #when switching from conv to fc layers, tensor must be flattened, \n",
    "        \n",
    "        #in_features = equals out_features from previous layer;\n",
    "        #out_features = size of output tensor, how many nodes we want in our layer\n",
    "        #out_features are often decreased among the layers, until number of output classes is reached\n",
    "        #bias standardly true\n",
    "        self.fc1 = nn.Linear(in_features = 12*4*4, out_features = 120) #linear, dense layers (fully connected = fc)\n",
    "        self.fc2 = nn.Linear(120, 60)\n",
    "        self.out = nn.Linear(60, 10)\n",
    "        \n",
    "    def forward(self, t): #implement the forward pass, takes tensor as arg\n",
    "        # (1) input layer, normally left away\n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        # (4) hidden linear layer (tensor is flattened)\n",
    "        t = t.reshape(-1, 12 * 4 * 4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t, dim = 1) #returns a probability for each of the prediction classes\n",
    "                                    #but we don't need it, as we do a cross-entropy loss which does that implicitly\n",
    "        return t\n",
    "    \n",
    "    #Overriding functions:\n",
    "    #def __repr__(self):\n",
    "     #   return \"Custom String that is returned upon calling a object of this class.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get an instance of your network\n",
    "network = Network()\n",
    "network\n",
    "#dot operation\n",
    "network.conv1\n",
    "network.conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-1.9318e-01, -1.7595e-01,  9.6386e-02, -1.3023e-01,  8.0897e-02],\n",
       "          [ 1.9020e-01,  8.9302e-02,  9.2500e-02, -1.2434e-01,  9.2441e-02],\n",
       "          [-1.4880e-01, -9.0718e-02, -1.0102e-02,  2.6926e-02,  6.5431e-02],\n",
       "          [ 1.9326e-01, -5.1948e-02,  1.6542e-03,  1.5422e-01,  1.2364e-01],\n",
       "          [-1.8403e-01,  1.9582e-01,  4.5460e-02, -2.7600e-02,  1.2842e-01]]],\n",
       "\n",
       "\n",
       "        [[[-9.6271e-02, -1.7077e-01, -1.6527e-01, -1.1869e-01,  4.2556e-02],\n",
       "          [ 1.8114e-01,  1.8478e-01,  1.7345e-01, -1.8819e-01,  1.8300e-01],\n",
       "          [-1.6325e-01, -1.4068e-01, -1.9204e-01, -1.2472e-01,  1.0422e-01],\n",
       "          [ 4.4858e-02, -1.4175e-01, -8.5904e-02,  1.0113e-01,  1.5243e-01],\n",
       "          [ 1.1321e-01, -4.3560e-02, -3.8096e-03,  1.0364e-01, -1.4136e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2315e-01,  9.0407e-02, -1.6540e-01, -7.6472e-02, -1.1830e-01],\n",
       "          [ 9.3949e-02,  2.1589e-02, -8.2750e-02,  1.1971e-01,  2.7289e-02],\n",
       "          [-6.6503e-02, -4.8604e-03,  1.4141e-01,  1.4356e-02, -1.8881e-01],\n",
       "          [-1.4574e-01, -1.1350e-01, -1.8913e-01,  6.4465e-02, -1.4122e-01],\n",
       "          [-5.4257e-02,  1.8602e-01,  1.9453e-01, -3.7591e-02, -1.4992e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.7647e-01, -1.9355e-01,  6.9926e-02, -1.4024e-01, -1.3123e-01],\n",
       "          [ 6.2094e-02,  1.7187e-01, -9.8770e-03, -2.4479e-03, -1.2521e-01],\n",
       "          [-6.6723e-02,  1.6046e-01, -1.1880e-01, -4.4395e-02, -1.5878e-01],\n",
       "          [ 1.2736e-02, -5.1952e-02, -2.7493e-02,  8.7811e-02, -5.2058e-02],\n",
       "          [ 1.2002e-01,  1.0540e-01,  3.8473e-02, -1.9245e-01, -9.6055e-02]]],\n",
       "\n",
       "\n",
       "        [[[-4.7840e-02,  1.3981e-01, -1.9223e-01,  1.7993e-01, -1.1446e-01],\n",
       "          [-6.7498e-02,  2.4716e-02,  7.0351e-03, -5.9182e-02,  1.9948e-01],\n",
       "          [ 4.3940e-02, -7.4978e-02, -5.2130e-02, -1.0280e-01, -1.0533e-01],\n",
       "          [ 1.4642e-01,  9.7463e-02, -1.2617e-01,  1.6448e-01,  7.0665e-02],\n",
       "          [-1.4056e-01,  9.7765e-02,  6.9426e-02, -1.3485e-01, -8.7102e-02]]],\n",
       "\n",
       "\n",
       "        [[[-7.6247e-02,  1.8470e-04, -1.0700e-01, -4.7311e-03,  4.4236e-02],\n",
       "          [-7.6824e-02, -1.2911e-02, -1.7962e-01, -5.1763e-02,  1.2974e-01],\n",
       "          [ 1.6754e-01, -1.8506e-01, -9.7812e-03,  1.7287e-01,  5.6368e-02],\n",
       "          [ 1.2639e-01,  1.7609e-01, -9.1100e-03,  7.5807e-02,  8.7096e-02],\n",
       "          [ 4.2600e-02,  9.3641e-02,  8.1754e-02,  7.9399e-02,  1.9563e-01]]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#access the weights of a layer, those are actually updated during learning, so that the loss function is minimized\n",
    "#this is done through the Parameter class: extends Tensor class\n",
    "# weights basically convert the number of in_channels to the respective number of out_channels\n",
    "network.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 6, 5, 5])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape of the weights is directly related to the hyperparameters that we specified\n",
    "# This shape / Tensor represents our whole filter / layer\n",
    "# Rank 4 tensors: number of filters, depth of filters, height and width of kernel / filter\n",
    "network.conv2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5, 5])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gives us a single filter:\n",
    "network.conv2.weight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 192])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear layers have rank 2 tensors\n",
    "# Height = output features, width = input features\n",
    "network.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t\t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias \t\t torch.Size([6])\n",
      "conv2.weight \t\t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t\t torch.Size([12])\n",
      "fc1.weight \t\t torch.Size([120, 192])\n",
      "fc1.bias \t\t torch.Size([120])\n",
      "fc2.weight \t\t torch.Size([60, 120])\n",
      "fc2.bias \t\t torch.Size([60])\n",
      "out.weight \t\t torch.Size([10, 60])\n",
      "out.bias \t\t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "#Show all parameters of the network:\n",
    "for name, param in network.named_parameters():\n",
    "    print(name, \"\\t\\t\", param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More explicit explanation in the seperat Loading Fashion MNIST Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = \"./data/FashionMNIST\"\n",
    "    , train = True\n",
    "    , download = True\n",
    "    , transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5)\n",
    "        \n",
    "        #table and formula to calculate the changes of img sizes:\n",
    "        # https://deeplizard.com/learn/video/cin4YcGBh3Q\n",
    "        self.fc1 = nn.Linear(in_features = 12*4*4, out_features = 120) #needed, because the img has the shape\n",
    "                                                                        #(1, 12, 4, 4) when it arrives at the fc\n",
    "                                                                        #because it is flattened, the input is 12*4*4\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        self.out = nn.Linear(in_features = 60, out_features = 10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        t = F.relu(self.fc1(t.reshape(-1, 12 * 4 * 4)))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        \n",
    "        t = self.out(t)\n",
    "        #normally softmax, but is implicitly included in the cross entropy \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7ff174da8410>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turning computational graph off, as we do not need it yet\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = sample\n",
    "image.shape #1 since gray, 28x28 for size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PyTorch only takes batches: in the format batch_size, in_channels, height, width\n",
    "# if size one, we need to unsqueeze the tensor\n",
    "image.unsqueeze(0).shape #gives us batch-size one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing a single image through our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = network(image.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape #shape means, one image in our batch, 10 prediction labels for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0239, -0.0650, -0.1267,  0.1285,  0.0236, -0.0431,  0.0312, -0.1431,\n",
       "         -0.0683, -0.0988]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label #what is the actual label for our img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax(dim=1) #of course that is wrong, because it is totally random and guessing (not trained yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1012, 0.0971, 0.0913, 0.1178, 0.1061, 0.0992, 0.1069, 0.0898, 0.0968,\n",
       "         0.0939]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if we want those values to be probabilities, we need to use softmax\n",
    "pred_prob = F.softmax(pred, dim = 1)\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing a whole batch of images through our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    train_set\n",
    "    , batch_size = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(data_loader)) #always gives us the amount of images according to batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 28, 28])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape #They have the proper shape to read into our network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape #10 images in our batch, one label per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = network(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape #10 images, each of those elemnts has 10 prediction classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1371,  0.0402,  0.0045, -0.1118, -0.1010, -0.0127, -0.0761,  0.0947,\n",
       "          0.0692,  0.1365],\n",
       "        [ 0.1277,  0.0440,  0.0172, -0.1112, -0.1006, -0.0030, -0.0801,  0.0978,\n",
       "          0.0779,  0.1260],\n",
       "        [ 0.1426,  0.0445,  0.0234, -0.1014, -0.1076, -0.0042, -0.0766,  0.1243,\n",
       "          0.0960,  0.1190],\n",
       "        [ 0.1384,  0.0446,  0.0182, -0.1100, -0.1017, -0.0004, -0.0797,  0.1154,\n",
       "          0.0874,  0.1240],\n",
       "        [ 0.1354,  0.0417,  0.0042, -0.1185, -0.0995, -0.0019, -0.0768,  0.1008,\n",
       "          0.0737,  0.1299],\n",
       "        [ 0.1336,  0.0538,  0.0179, -0.1117, -0.1041, -0.0045, -0.0849,  0.0957,\n",
       "          0.0789,  0.1290],\n",
       "        [ 0.1413,  0.0410,  0.0173, -0.1188, -0.1097, -0.0007, -0.0817,  0.1020,\n",
       "          0.0857,  0.1283],\n",
       "        [ 0.1316,  0.0535,  0.0165, -0.1140, -0.0991, -0.0076, -0.0840,  0.0920,\n",
       "          0.0703,  0.1324],\n",
       "        [ 0.1352,  0.0438,  0.0156, -0.1059, -0.0995, -0.0062, -0.0780,  0.1122,\n",
       "          0.0891,  0.1213],\n",
       "        [ 0.1276,  0.0481,  0.0244, -0.0894, -0.1016, -0.0151, -0.0786,  0.1079,\n",
       "          0.0815,  0.1241]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 9, 0, 0])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim = 1) #highest prediction index for every \"row\" bzw. for every image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels #correct labels of those pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True, False,  True, False, False, False, False, False])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim = 1).eq(labels) #comparing prediction to correct label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim = 1).eq(labels).sum() #How many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing a function that does this for us:\n",
    "def get_num_correct(predictions, labels):\n",
    "    return 'Correctly classified: {}'.format(predictions.argmax(dim = 1).eq(labels).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Correctly classified: 3'"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_correct(preds, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7ff1566bc990>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim \n",
    "torch.set_grad_enabled(True) #by default turned on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function that gives us the amount of correct predicted labels:\n",
    "def get_num_correct(predictions, labels):\n",
    "    return 'Correctly classified: {}'.format(predictions.argmax(dim = 1).eq(labels).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The network is defined above, we initialize a new one:\n",
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = \"./data/FashionMNIST\"\n",
    "    , train = True\n",
    "    , download = True\n",
    "    , transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get batches from loaded train_set\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set\n",
    "    , batch_size = 100\n",
    ")\n",
    "batch = next(iter(train_loader))\n",
    "images, labels = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.322381019592285"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = network(images)\n",
    "loss = F.cross_entropy(preds, labels) #calculating loss with cross entropy, should decrease during training\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(network.conv1.weight.grad) #no gradients for this layer before calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward() #Calculating the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 5, 5])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv1.weight.grad.shape #gradients have been updated for every weight\n",
    "\n",
    "#this gradient tensor has the same shape as the weight tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the optimizer: we use Adam and give it the trainable parameters of our network\n",
    "optimizer = optim.Adam(network.parameters(), lr = 0.01) #SGD works as well, lr = hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.322381019592285"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Correctly classified: 5'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_correct(preds, labels) #makes sense, since it is only guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the weights:\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again, calculating the loss:\n",
    "preds = network(images)\n",
    "loss = F.cross_entropy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2961061000823975"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item() #should be lower now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Correctly classified: 10'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_correct(preds, labels) #there we go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All this summarized: Training with one batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1:  2.2991673946380615\n",
      "loss2:  2.278111457824707\n"
     ]
    }
   ],
   "source": [
    "#This is a good way to test the network first, but normally everything is done in a training loop\n",
    "network = Network()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set\n",
    "    , batch_size = 100\n",
    ")\n",
    "optimizer = optim.Adam(network.parameters(), lr = 0.01) #or SDG, ... lr must be tested and tuned!!!\n",
    "\n",
    "batch = next(iter(train_loader)) #get batch\n",
    "images, labels = batch\n",
    "\n",
    "preds = network(images) #pass batch\n",
    "loss = F.cross_entropy(preds, labels) #calculate loss\n",
    "\n",
    "loss.backward() #calculate gradients backward = short for backpropagation\n",
    "optimizer.step() #update weights\n",
    "\n",
    "#--------------------------------------------------------\n",
    "print(\"loss1: \", loss.item())\n",
    "preds = network(images)\n",
    "loss = F.cross_entropy(preds, labels)\n",
    "print(\"loss2: \", loss.item()) #loss should have decreased with second iteration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training all batches but only one epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(predictions, labels):\n",
    "    return predictions.argmax(dim = 1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 total correct:  46426 loss:  354.02324908971786\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "\n",
    "#changing the batch-size results in changing the number of times the weights are updated\n",
    "# bigger batches, means less iterations, less weight updating\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set\n",
    "    , batch_size = 100\n",
    ")\n",
    "optimizer = optim.Adam(network.parameters(), lr = 0.01)\n",
    "\n",
    "total_loss = 0\n",
    "total_correct = 0\n",
    "\n",
    "for batch in train_loader: #600 iterations\n",
    "    images, labels = batch\n",
    "\n",
    "    preds = network(images) #pass batch\n",
    "    loss = F.cross_entropy(preds, labels) #calculate loss\n",
    "    \n",
    "    optimizer.zero_grad() #must be done, because pytorch accumulates all gradients, this\n",
    "                            # puts them to zero again\n",
    "    loss.backward() #calculate gradients backward\n",
    "    optimizer.step() #update weights\n",
    "    \n",
    "    total_loss += loss.item()\n",
    "    total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "print(\"epoch: \", 0, \"total correct: \", total_correct, \"loss: \", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7737666666666667"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy:\n",
    "total_correct / len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 total correct:  47616 loss:  327.9524929225445\n",
      "epoch:  1 total correct:  51824 loss:  222.88604319095612\n",
      "epoch:  2 total correct:  52574 loss:  203.97988931834698\n",
      "epoch:  3 total correct:  52929 loss:  194.08124616742134\n",
      "epoch:  4 total correct:  53089 loss:  188.72502356767654\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set\n",
    "    , batch_size = 100\n",
    ")\n",
    "optimizer = optim.Adam(network.parameters(), lr = 0.01)\n",
    "for epoch in range(5):\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "\n",
    "        preds = network(images)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "    \n",
    "        optimizer.zero_grad() #gradients must be put to zero, would accumulate otherwise\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    print(\"epoch: \", epoch, \"total correct: \", total_correct, \"loss: \", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.48166666666667"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy:\n",
    "total_correct / len(train_set)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The network improvement often hits a plateau, after it made big steps in the beginning. This means, hyperparameter tuning or other tuning should be done. What if the model sucks overall? This might be due to underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All we need: A tensor of predictions and the corresponding labels\n",
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function that gives us all predictions within one tensor:\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        \n",
    "        preds = model(images) #pass the image to the model\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds, preds)\n",
    "        , dim = 0\n",
    "        )\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we should turn the gradient tracking/graph off, since we are not training the model,\n",
    "# we are inferring / predicting\n",
    "#This is faster and uses less memory (because of leaving away the graph)\n",
    "with torch.no_grad(): #this is the locally way of turning it off, not globally\n",
    "    pred_loader = torch.utils.data.DataLoader(train_set, batch_size = 5000)\n",
    "    train_preds = get_all_preds(network, pred_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the whole training set, with the predictions for every class\n",
    "train_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total correct:  53132\n",
      "accuracy%:  88.55333333333333\n"
     ]
    }
   ],
   "source": [
    "#Get the amount of correct preds:\n",
    "preds_correct = get_num_correct(train_preds, train_set.targets)\n",
    "\n",
    "print(\"total correct: \", preds_correct)\n",
    "print(\"accuracy%: \", preds_correct / len(train_set)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have 10 predictions per img, so we need the highest prediction:\n",
    "train_preds.argmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torch.stack function:\n",
    "stacked = torch.stack(\n",
    "    (\n",
    "    train_set.targets\n",
    "    , train_preds.argmax(dim = 1)\n",
    "    )\n",
    "    , dim = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 2])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.shape #60.000 img with 2 values each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 9],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [3, 3],\n",
       "        [0, 0],\n",
       "        [5, 5]])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked #those two values are the true label and the predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 9]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How to access items in this list?\n",
    "stacked[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiating the confusion matrix tensor\n",
    "confm = torch.zeros(10, 10, dtype = torch.int64) #10x10 because of 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11398,    10,   184,    92,    20,     0,   236,     0,    58,     2],\n",
       "        [   80, 11744,     6,   124,     6,     8,    22,     0,     6,     4],\n",
       "        [  228,     0, 10266,    84,   810,     2,   560,     0,    46,     4],\n",
       "        [  736,   218,    42, 10310,   440,     8,   182,     0,    32,    32],\n",
       "        [   52,     8,  1128,   374,  9782,     0,   636,     0,    20,     0],\n",
       "        [    2,     0,     0,     2,     0, 11344,     0,   486,     6,   160],\n",
       "        [ 3336,    20,  1004,   140,   902,     6,  6490,     0,    98,     4],\n",
       "        [    0,     0,     0,     0,     0,    36,     0, 11816,     6,   142],\n",
       "        [   70,     8,    24,    10,    16,    26,    90,    26, 11728,     2],\n",
       "        [    0,     0,     0,     0,     0,    24,     0,   582,     8, 11386]])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filling the confmatrix:\n",
    "for pair in stacked:\n",
    "    true, predicted = pair  #access the pair\n",
    "    confm[true, predicted] = confm[true, predicted] + 1 #increase the \"cell\" by one\n",
    "confm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize it:\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to plot the conf matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5699,    5,   92,   46,   10,    0,  118,    0,   29,    1],\n",
       "       [  40, 5872,    3,   62,    3,    4,   11,    0,    3,    2],\n",
       "       [ 114,    0, 5133,   42,  405,    1,  280,    0,   23,    2],\n",
       "       [ 368,  109,   21, 5155,  220,    4,   91,    0,   16,   16],\n",
       "       [  26,    4,  564,  187, 4891,    0,  318,    0,   10,    0],\n",
       "       [   1,    0,    0,    1,    0, 5672,    0,  243,    3,   80],\n",
       "       [1668,   10,  502,   70,  451,    3, 3245,    0,   49,    2],\n",
       "       [   0,    0,    0,    0,    0,   18,    0, 5908,    3,   71],\n",
       "       [  35,    4,   12,    5,    8,   13,   45,   13, 5864,    1],\n",
       "       [   0,    0,    0,    0,    0,   12,    0,  291,    4, 5693]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This function does exactly the same as we did\n",
    "cm = confusion_matrix(train_set.targets, train_preds.argmax(dim=1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[5699    5   92   46   10    0  118    0   29    1]\n",
      " [  40 5872    3   62    3    4   11    0    3    2]\n",
      " [ 114    0 5133   42  405    1  280    0   23    2]\n",
      " [ 368  109   21 5155  220    4   91    0   16   16]\n",
      " [  26    4  564  187 4891    0  318    0   10    0]\n",
      " [   1    0    0    1    0 5672    0  243    3   80]\n",
      " [1668   10  502   70  451    3 3245    0   49    2]\n",
      " [   0    0    0    0    0   18    0 5908    3   71]\n",
      " [  35    4   12    5    8   13   45   13 5864    1]\n",
      " [   0    0    0    0    0   12    0  291    4 5693]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = (\"T-shirt/top\", \"Trouser\", \"Pullover\", \"DressCoat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(cm, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We can also plot a normalized conf matrix:\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(cm, names, normalize = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "ipy_base",
   "language": "python",
   "name": "ipy_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
