{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a RunBuilder, RunManager and use those classes in the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for our classes\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "import time\n",
    "#import torch #normally gets imported anyway... let's see!\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "#We can import our classes like this now:\n",
    "from run_classes import RunBuilder, RunManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand, look at the Tensorboard JN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "        \n",
    "        runs = []\n",
    "        \n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "            \n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        \n",
    "        #can further be refactored by extracting this\n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "        \n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "    \n",
    "    def begin_run(self, run, network, loader):\n",
    "        \n",
    "        self.run_start_time = time.time()\n",
    "        \n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        \n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment = f' Run {self.run_count} with {run}')\n",
    "        \n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        self.tb.add_image('images', grid)\n",
    "        self.tb.add_graph(self.network, images)\n",
    "        \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        \n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "        \n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "        \n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "        \n",
    "        results = OrderedDict()\n",
    "        results['run'] = self.run_count\n",
    "        results['epoch'] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results['accuracy'] = accuracy\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        results['run duration'] = run_duration\n",
    "        \n",
    "        for k, v in self.run_params._asdict().items(): results[k] = v\n",
    "        self.run_data.append(results)\n",
    "        table = pd.DataFrame.from_dict(self.run_data, orient = 'columns')\n",
    "        \n",
    "        clear_output(wait = True)\n",
    "        display(table)\n",
    "        \n",
    "    def track_loss(self, loss):\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "        \n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim = 1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, fileName):\n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data\n",
    "            , orient = 'columns'\n",
    "        ).to_csv(f'{fileName}.csv')\n",
    "        \n",
    "        with open(f'{fileName}.csv', 'w', encoding = 'utf-8') as f:\n",
    "                 json.dump(self.run_data, f, ensure_ascii = False, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Network, TrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = \"./data/FashionMNIST\"\n",
    "    , train = True\n",
    "    , download = True\n",
    "    , transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_normal = torchvision.datasets.FashionMNIST(\n",
    "    root = \"./data/FashionMNIST\"\n",
    "    , train = True\n",
    "    , download = True\n",
    "    , transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        #Normalize Dataset?\n",
    "            # normally per feature - meaning per color channel (most often 3, in this case 1)\n",
    "        \n",
    "        #Mean and std calculated in below cell\n",
    "        #Objective is to move the mean to 0 and std to 1 \n",
    "        , transforms.Normalize(mean = [0.2859], std = [0.3530])\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2859), tensor(0.3530))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the mean and std for the transformer\n",
    "loader = torch.utils.data.DataLoader(train_set, batch_size=len(train_set), num_workers = 1)\n",
    "data = next(iter(loader))\n",
    "data[0].mean(), data[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsets = {\n",
    "    'not_normal': train_set\n",
    "    , 'normal': train_set_normal\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5)\n",
    "        \n",
    "        #table and formula to calculate the changes of img sizes:\n",
    "        # https://deeplizard.com/learn/video/cin4YcGBh3Q\n",
    "        self.fc1 = nn.Linear(in_features = 12*4*4, out_features = 120) #needed, because the img has the shape\n",
    "                                                                        #(1, 12, 4, 4) when it arrives at the fc\n",
    "                                                                        #because it is flattened, the input is 12*4*4\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        self.out = nn.Linear(in_features = 60, out_features = 10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        t = F.relu(self.fc1(t.reshape(-1, 12 * 4 * 4)))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        \n",
    "        t = self.out(t)\n",
    "        #normally softmax, but is implicitly included in the cross entropy \n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Training Loop now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607315</td>\n",
       "      <td>0.764600</td>\n",
       "      <td>13.668535</td>\n",
       "      <td>15.201364</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585218</td>\n",
       "      <td>0.780200</td>\n",
       "      <td>10.700406</td>\n",
       "      <td>11.172200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572106</td>\n",
       "      <td>0.781383</td>\n",
       "      <td>10.679205</td>\n",
       "      <td>10.842438</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.573679</td>\n",
       "      <td>0.780917</td>\n",
       "      <td>11.166654</td>\n",
       "      <td>11.349237</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.003109</td>\n",
       "      <td>0.615567</td>\n",
       "      <td>15.952430</td>\n",
       "      <td>16.732734</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.003832</td>\n",
       "      <td>0.616867</td>\n",
       "      <td>12.589240</td>\n",
       "      <td>13.464185</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947843</td>\n",
       "      <td>0.637217</td>\n",
       "      <td>12.450007</td>\n",
       "      <td>13.337946</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983083</td>\n",
       "      <td>0.625083</td>\n",
       "      <td>12.482737</td>\n",
       "      <td>13.385255</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "0    1      1  0.607315  0.764600       13.668535     15.201364  0.01   \n",
       "1    2      1  0.585218  0.780200       10.700406     11.172200  0.01   \n",
       "2    3      1  0.572106  0.781383       10.679205     10.842438  0.01   \n",
       "3    4      1  0.573679  0.780917       11.166654     11.349237  0.01   \n",
       "4    5      1  1.003109  0.615567       15.952430     16.732734  0.01   \n",
       "5    6      1  1.003832  0.616867       12.589240     13.464185  0.01   \n",
       "6    7      1  0.947843  0.637217       12.450007     13.337946  0.01   \n",
       "7    8      1  0.983083  0.625083       12.482737     13.385255  0.01   \n",
       "\n",
       "   batch_size  shuffle  num_workers  epochs  \n",
       "0         100     True            0       1  \n",
       "1         100     True            1       1  \n",
       "2         100     True            2       1  \n",
       "3         100     True            4       1  \n",
       "4        1000     True            0       1  \n",
       "5        1000     True            1       1  \n",
       "6        1000     True            2       1  \n",
       "7        1000     True            4       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    , batch_size = [100, 1000]\n",
    "    , shuffle =[True]\n",
    "    , num_workers = [0, 1, 2, 4] #1 seems to give the best results\n",
    "    , epochs = [1]\n",
    "    , train_sets = ['not_normal', 'normal']\n",
    ")\n",
    "\n",
    "rm = RunManager()\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    \n",
    "    network = Network()\n",
    "    loader = torch.utils.data.DataLoader(trainsets[run.train_sets]\n",
    "                                         , batch_size = run.batch_size\n",
    "                                         , shuffle = run.shuffle\n",
    "                                         , num_workers = run.num_workers\n",
    "                                        )\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr = run.lr)\n",
    "    \n",
    "    rm.begin_run(run, network, loader)\n",
    "    for epoch in range(run.epochs):\n",
    "        \n",
    "        rm.begin_epoch()\n",
    "        for batch in loader:\n",
    "            \n",
    "            images, labels = batch[0], batch[1]\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            rm.track_loss(loss)\n",
    "            rm.track_num_correct(preds, labels)\n",
    "            \n",
    "        rm.end_epoch()\n",
    "    rm.end_run()\n",
    "#m.save('results') #create csv file with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipy_base",
   "language": "python",
   "name": "ipy_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
