{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the nn.Sequential() module for easier CNN creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from run_classes import RunBuilder, RunManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = \"./data/FashionMNIST\"\n",
    "    , train = True\n",
    "    , download = True\n",
    "    , transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_features = img.numel()\n",
    "in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This can be playes with\n",
    "out_features = math.floor(in_features / 2)\n",
    "out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_classes = len(train_set.classes)\n",
    "out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): Linear(in_features=784, out_features=392, bias=True)\n",
       "  (2): Linear(in_features=392, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = nn.Sequential(\n",
    "    nn.Flatten(start_dim = 1)\n",
    "    , nn.Linear(in_features, out_features)\n",
    "    , nn.Linear(out_features, out_classes)\n",
    ")\n",
    "net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=392, bias=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = img.unsqueeze(0) #unsqueeze\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1510,  0.0812,  0.0858,  0.0926,  0.0241, -0.1825,  0.0839,  0.0868,\n",
       "          0.2423, -0.0405]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('flat', Flatten()),\n",
       "             ('linear', Linear(in_features=784, out_features=392, bias=True)),\n",
       "             ('out', Linear(in_features=392, out_features=10, bias=True))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = OrderedDict([\n",
    "    ('flat', nn.Flatten(start_dim = 1)),\n",
    "    ('linear', nn.Linear(in_features, out_features)),\n",
    "    ('out', nn.Linear(out_features, out_classes))\n",
    "])\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (flat): Flatten()\n",
       "  (linear): Linear(in_features=784, out_features=392, bias=True)\n",
       "  (out): Linear(in_features=392, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = nn.Sequential(layers)\n",
    "net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1510,  0.0812,  0.0858,  0.0926,  0.0241, -0.1825,  0.0839,  0.0868,\n",
       "           0.2423, -0.0405]], grad_fn=<AddmmBackward>),\n",
       " tensor([[ 0.1804, -0.1383, -0.0181, -0.0633,  0.3174, -0.0770,  0.2227,  0.0905,\n",
       "           0.2683,  0.0203]], grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1(image), net2(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flatten()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can access those layers by their given name\n",
    "net2.flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=392, out_features=10, bias=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add modules\n",
    "\n",
    "net2.add_module('output', nn.Linear(out_classes, out_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (flat): Flatten()\n",
       "  (linear): Linear(in_features=784, out_features=392, bias=True)\n",
       "  (out): Linear(in_features=392, out_features=10, bias=True)\n",
       "  (output): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the same NN as before with nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Flatten()\n",
       "  (7): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (10): ReLU()\n",
       "  (11): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n",
    "    , nn.ReLU()\n",
    "    , nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "    , nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5)\n",
    "    , nn.ReLU()\n",
    "    , nn.MaxPool2d(kernel_size =2, stride = 2)\n",
    "    \n",
    "    , nn.Flatten(start_dim = 1)\n",
    "    , nn.Linear(in_features = 12*4*4, out_features = 120)\n",
    "    , nn.ReLU()\n",
    "    , nn.Linear(in_features = 120, out_features = 60)\n",
    "    , nn.ReLU()\n",
    "    , nn.Linear(in_features = 60, out_features = 10)\n",
    ")\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... works also in the other 2 ways as demonstrated before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing BatchNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalizing activations after a particular layer - in that way data is normalized before it hits the next layer  \n",
    "Inside a batch-norm layer, learnable parameters exist, such as scale and shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (5): ReLU()\n",
       "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (7): Flatten()\n",
       "  (8): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (9): ReLU()\n",
       "  (10): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (12): ReLU()\n",
       "  (13): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_bn = nn.Sequential(\n",
    "    #2D because we deal with pictures\n",
    "    nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n",
    "    , nn.ReLU()\n",
    "    , nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "    ## set right before next layer, 6 for number of in_channels = same as out_channels\n",
    "    , nn.BatchNorm2d(6)\n",
    "    , nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5)\n",
    "    , nn.ReLU()\n",
    "    , nn.MaxPool2d(kernel_size =2, stride = 2)\n",
    "    \n",
    "    , nn.Flatten(start_dim = 1)\n",
    "    , nn.Linear(in_features = 12*4*4, out_features = 120)\n",
    "    , nn.ReLU()\n",
    "    ##\n",
    "    , nn.BatchNorm1d(120)\n",
    "    , nn.Linear(in_features = 120, out_features = 60)\n",
    "    , nn.ReLU()\n",
    "    ## 1D because we Flattened our data\n",
    "    , nn.BatchNorm1d(60)\n",
    "    , nn.Linear(in_features = 60, out_features = 10)\n",
    ")\n",
    "net_bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's test the NNs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_normal = train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = \"./data/FashionMNIST\"\n",
    "    , train = True\n",
    "    , download = True\n",
    "    , transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        , transforms.Normalize(mean = [0.2859], std = [0.3530])\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining testing dics\n",
    "trainsets = {\n",
    "    'normal': train_set_normal,\n",
    "    'not_normal': train_set\n",
    "}\n",
    "\n",
    "networks = {\n",
    "    'net': net,\n",
    "    'net_bn': net_bn\n",
    "}\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    , batch_size = [1000]\n",
    "    , num_workers = [1]\n",
    "    , epochs = [1]\n",
    "    , trainset = list(trainsets.keys())\n",
    "    , network = list(networks.keys())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>epochs</th>\n",
       "      <th>trainset</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.836251</td>\n",
       "      <td>0.680200</td>\n",
       "      <td>11.528177</td>\n",
       "      <td>12.404298</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548108</td>\n",
       "      <td>0.801550</td>\n",
       "      <td>13.414044</td>\n",
       "      <td>14.417874</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>net_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.711222</td>\n",
       "      <td>0.761450</td>\n",
       "      <td>12.491821</td>\n",
       "      <td>13.487617</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.373756</td>\n",
       "      <td>0.861317</td>\n",
       "      <td>14.123362</td>\n",
       "      <td>15.149796</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>net_bn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "0    1      1  0.836251  0.680200       11.528177     12.404298  0.01   \n",
       "1    2      1  0.548108  0.801550       13.414044     14.417874  0.01   \n",
       "2    3      1  0.711222  0.761450       12.491821     13.487617  0.01   \n",
       "3    4      1  0.373756  0.861317       14.123362     15.149796  0.01   \n",
       "\n",
       "   batch_size  num_workers  epochs    trainset network  \n",
       "0        1000            1       1      normal     net  \n",
       "1        1000            1       1      normal  net_bn  \n",
       "2        1000            1       1  not_normal     net  \n",
       "3        1000            1       1  not_normal  net_bn  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Training Loop\n",
    "\n",
    "m = RunManager()\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    network = networks[run.network]\n",
    "    loader = DataLoader(trainsets[run.trainset], batch_size = run.batch_size, num_workers = run.num_workers)\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr = run.lr)\n",
    "    \n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(run.epochs):\n",
    "        m.begin_epoch()\n",
    "        \n",
    "        for batch in loader:\n",
    "            images, labels = batch\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipy_base",
   "language": "python",
   "name": "ipy_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
